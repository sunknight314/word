"""
AIæ®µè½åˆ†ææœåŠ¡ - é‡æ„åçš„ç»Ÿä¸€æ¶æ„
"""

import os
import json
from datetime import datetime
from typing import Dict, List, Any, Tuple
from .ai_client_base import AIClientBase
from .document_processor import DocumentProcessor


class AIAnalyzer(AIClientBase):
    """AIæ®µè½åˆ†ææœåŠ¡ç±»"""
    
    def __init__(self, api_base_url: str = None, api_key: str = None, model: str = None, model_config: str = None):
        """
        åˆå§‹åŒ–AIåˆ†æå™¨
        
        Args:
            api_base_url: APIåŸºç¡€URL
            api_key: APIå¯†é’¥
            model: æ¨¡å‹åç§°
            model_config: æ¨¡å‹é…ç½®åç§°
        """
        # åˆå§‹åŒ–åŸºç±»
        super().__init__(api_base_url, api_key, model, model_config)
        
        # åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
        self.document_processor = DocumentProcessor()
        
        # ç»“æœä¿å­˜é…ç½®
        self.save_results = True
        self.results_dir = "ai_analysis_results"
        self._ensure_results_dir()
    
    def get_prompts(self, input_data: List[Dict]) -> Tuple[str, str]:
        """
        è·å–æ®µè½åˆ†æçš„ç³»ç»Ÿå’Œç”¨æˆ·æç¤ºè¯
        
        Args:
            input_data: æ®µè½æ•°æ®åˆ—è¡¨
            
        Returns:
            (system_prompt, user_prompt) å…ƒç»„
        """
        from .ai_prompts import get_paragraph_analysis_prompt
        return get_paragraph_analysis_prompt(input_data)
    
    async def process_ai_response(self, ai_response: str) -> Dict[str, Any]:
        """
        å¤„ç†AIå“åº”ï¼Œè§£ææ®µè½åˆ†æç»“æœ
        
        Args:
            ai_response: AIåŸå§‹å“åº”
            
        Returns:
            å¤„ç†åçš„åˆ†æç»“æœ
        """
        try:
            print("ğŸ” å¼€å§‹æå–æ®µè½åˆ†æJSON...")
            json_content = self.extract_json_from_content(ai_response)
            print(f"ğŸ“‹ æå–çš„JSONé•¿åº¦: {len(json_content)} å­—ç¬¦")
            
            analysis_result = json.loads(json_content)
            print("âœ… æ®µè½åˆ†æJSONè§£ææˆåŠŸ")
            
            return {
                "success": True,
                "analysis_result": analysis_result.get("analysis_result", []),
                "raw_response": ai_response
            }
            
        except json.JSONDecodeError as e:
            print(f"âŒ æ®µè½åˆ†æJSONè§£æå¤±è´¥: {str(e)}")
            if 'json_content' in locals():
                print(f"ğŸ” å°è¯•è§£æçš„å†…å®¹: {json_content}")
            else:
                print("ğŸ” json_contentå˜é‡æœªå®šä¹‰")
            return {
                "success": False,
                "error": f"JSONè§£æå¤±è´¥: {str(e)}",
                "raw_response": ai_response
            }
    
    async def analyze_paragraphs(self, paragraphs_data: List[Dict]) -> Dict[str, Any]:
        """
        åˆ†ææ®µè½ç±»å‹ï¼ˆä¸€æ¬¡æ€§å¤„ç†ï¼‰
        
        Args:
            paragraphs_data: æ®µè½æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å«paragraph_numberå’Œpreview_text
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            print(f"ğŸ“„ å¼€å§‹åˆ†æ {len(paragraphs_data)} ä¸ªæ®µè½...")
            
            # ç›´æ¥ä½¿ç”¨AIåˆ†æï¼Œä¸€æ¬¡æ€§å¤„ç†
            result = await self.analyze(paragraphs_data)
            
            # ä¿å­˜åˆ†æç»“æœ
            if self.save_results and result.get("success"):
                self._save_analysis_result(result, paragraphs_data)
            
            return result
            
        except Exception as e:
            import traceback
            error_detail = f"{str(e)}\n{traceback.format_exc()}"
            error_result = {
                "success": False,
                "error": error_detail,
                "total_paragraphs": len(paragraphs_data)
            }
            
            # å³ä½¿å¤±è´¥ä¹Ÿä¿å­˜é”™è¯¯ä¿¡æ¯
            if self.save_results:
                self._save_analysis_result(error_result, paragraphs_data, is_error=True)
            
            return error_result
    
    def create_mock_analysis(self, paragraphs_data: List[Dict]) -> Dict[str, Any]:
        """
        åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœï¼ˆç”¨äºæµ‹è¯•ï¼‰
        
        Args:
            paragraphs_data: æ®µè½æ•°æ®åˆ—è¡¨
            
        Returns:
            æ¨¡æ‹Ÿçš„åˆ†æç»“æœ
        """
        analysis_result = []
        
        for para in paragraphs_data:
            preview = para["preview_text"]
            para_num = para["paragraph_number"]
            
            # ç®€å•çš„è§„åˆ™åˆ¤æ–­ï¼ˆæ¨¡æ‹ŸAIåˆ†æï¼‰
            if "æ–‡æ¡£" in preview and para_num == 1:
                para_type = "title"
                confidence = 0.95
                reason = "æ–‡æ¡£æ ‡é¢˜ï¼Œä½äºç¬¬ä¸€æ®µ"
            elif preview.startswith("ç¬¬") and "ç« " in preview:
                para_type = "heading1"
                confidence = 0.92
                reason = "ä½¿ç”¨'ç¬¬Xç« 'æ ¼å¼çš„ä¸€çº§æ ‡é¢˜"
            elif preview.count(".") == 1 and preview[0].isdigit():
                para_type = "heading2"
                confidence = 0.88
                reason = "ä½¿ç”¨'X.X'æ ¼å¼çš„äºŒçº§æ ‡é¢˜"
            elif preview.count(".") == 2 and preview[0].isdigit():
                para_type = "heading3"
                confidence = 0.85
                reason = "ä½¿ç”¨'X.X.X'æ ¼å¼çš„ä¸‰çº§æ ‡é¢˜"
            elif len(preview) <= 15 and not preview.endswith("ï¼Œ"):
                para_type = "heading4"
                confidence = 0.75
                reason = "çŸ­æ–‡æœ¬ï¼Œå¯èƒ½æ˜¯ä½çº§æ ‡é¢˜"
            else:
                para_type = "paragraph"
                confidence = 0.80
                reason = "æ­£æ–‡æ®µè½ç‰¹å¾"
            
            analysis_result.append({
                "paragraph_number": para_num,
                "preview_text": preview,
                "type": para_type,
                "confidence": confidence,
                "reason": reason
            })
        
        return {
            "analysis_result": analysis_result
        }
    
    def _ensure_results_dir(self):
        """ç¡®ä¿ç»“æœä¿å­˜ç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
            print(f"ğŸ“ åˆ›å»ºAIåˆ†æç»“æœç›®å½•: {self.results_dir}")
    
    def _save_analysis_result(self, result: Dict[str, Any], paragraphs_data: List[Dict], is_error: bool = False):
        """
        ä¿å­˜AIåˆ†æç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            result: åˆ†æç»“æœ
            paragraphs_data: åŸå§‹æ®µè½æ•°æ®
            is_error: æ˜¯å¦ä¸ºé”™è¯¯ç»“æœ
        """
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            status = "error" if is_error else "success"
            filename = f"ai_analysis_{status}_{timestamp}.json"
            filepath = os.path.join(self.results_dir, filename)
            
            # å‡†å¤‡ä¿å­˜çš„æ•°æ®
            save_data = {
                "timestamp": datetime.now().isoformat(),
                "model": self.model,
                "status": status,
                "input_data": {
                    "total_paragraphs": len(paragraphs_data),
                    "paragraphs": paragraphs_data
                },
                "analysis_result": result
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ AIåˆ†æç»“æœå·²ä¿å­˜: {filepath}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜AIåˆ†æç»“æœå¤±è´¥: {str(e)}")