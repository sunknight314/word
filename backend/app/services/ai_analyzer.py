"""
å¤§æ¨¡å‹åˆ†ææœåŠ¡
"""

import json
import httpx
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from app.services.ai_prompts import get_analysis_prompt


class AIAnalyzer:
    """å¤§æ¨¡å‹åˆ†ææœåŠ¡ç±»"""
    
    def __init__(self, api_base_url: str = None, api_key: str = None, model: str = None):
        """
        åˆå§‹åŒ–AIåˆ†æå™¨
        
        Args:
            api_base_url: APIåŸºç¡€URL
            api_key: APIå¯†é’¥
            model: æ¨¡å‹åç§°
        """
        # ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„é…ç½®
        self.api_base_url = api_base_url or "https://api.siliconflow.cn/v1"
        self.api_key = api_key or "sk-ennjwzgywmisvlgqcumcojemtajhzmcowpmoothwmlklrzcn"
        self.model = model or "deepseek-ai/DeepSeek-V2.5"
        
        # HTTPå®¢æˆ·ç«¯é…ç½®
        self.timeout = 60.0  # å¢åŠ è¶…æ—¶æ—¶é—´
        self.max_retries = 3
        
        # ç»“æœä¿å­˜é…ç½®
        self.save_results = True
        self.results_dir = "ai_analysis_results"
        self._ensure_results_dir()
    
    async def analyze_paragraphs(self, paragraphs_data: List[Dict]) -> Dict[str, Any]:
        """
        åˆ†ææ®µè½ç±»å‹ï¼ˆæ”¯æŒåˆ†æ‰¹å¤„ç†å¤§æ–‡æ¡£ï¼‰
        
        Args:
            paragraphs_data: æ®µè½æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å«paragraph_numberå’Œpreview_text
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            # å¦‚æœæ®µè½æ•°è¶…è¿‡10ä¸ªï¼Œè¿›è¡Œåˆ†æ‰¹å¤„ç†
            if len(paragraphs_data) > 10:
                result = await self._analyze_paragraphs_in_batches(paragraphs_data)
            else:
                result = await self._analyze_single_batch(paragraphs_data)
            
            # ä¿å­˜åˆ†æç»“æœ
            if self.save_results and result.get("success"):
                self._save_analysis_result(result, paragraphs_data)
            
            return result
            
        except Exception as e:
            import traceback
            error_detail = f"{str(e)}\n{traceback.format_exc()}"
            error_result = {
                "success": False,
                "error": error_detail,
                "total_paragraphs": len(paragraphs_data)
            }
            
            # å³ä½¿å¤±è´¥ä¹Ÿä¿å­˜é”™è¯¯ä¿¡æ¯
            if self.save_results:
                self._save_analysis_result(error_result, paragraphs_data, is_error=True)
            
            return error_result
    
    async def _analyze_single_batch(self, paragraphs_data: List[Dict]) -> Dict[str, Any]:
        """
        åˆ†æå•æ‰¹æ®µè½
        """
        # ç”Ÿæˆprompt
        prompt = get_analysis_prompt(paragraphs_data)
        
        # è°ƒç”¨å¤§æ¨¡å‹API
        response = await self._call_ai_api(prompt)
        
        # è§£æå“åº”
        analysis_result = self._parse_ai_response(response)
        
        return {
            "success": True,
            "result": analysis_result,
            "total_paragraphs": len(paragraphs_data)
        }
    
    async def _analyze_paragraphs_in_batches(self, paragraphs_data: List[Dict]) -> Dict[str, Any]:
        """
        åˆ†æ‰¹å¤„ç†å¤§æ–‡æ¡£
        """
        batch_size = 8  # æ¯æ‰¹å¤„ç†8ä¸ªæ®µè½
        all_results = []
        
        print(f"ğŸ“¦ æ–‡æ¡£è¾ƒå¤§ï¼Œåˆ†æ‰¹å¤„ç†: {len(paragraphs_data)}ä¸ªæ®µè½ï¼Œæ¯æ‰¹{batch_size}ä¸ª")
        
        for i in range(0, len(paragraphs_data), batch_size):
            batch = paragraphs_data[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(paragraphs_data) + batch_size - 1) // batch_size
            
            print(f"  ğŸ“„ å¤„ç†ç¬¬{batch_num}æ‰¹ (å…±{total_batches}æ‰¹): æ®µè½{batch[0]['paragraph_number']}-{batch[-1]['paragraph_number']}")
            
            try:
                batch_result = await self._analyze_single_batch(batch)
                
                if batch_result["success"]:
                    batch_analysis = batch_result["result"]["analysis_result"]
                    all_results.extend(batch_analysis)
                    print(f"  âœ… ç¬¬{batch_num}æ‰¹å®Œæˆ")
                else:
                    print(f"  âŒ ç¬¬{batch_num}æ‰¹å¤±è´¥: {batch_result['error'][:100]}...")
                    # å¦‚æœæŸæ‰¹å¤±è´¥ï¼Œå¯ä»¥ç»§ç»­å¤„ç†å…¶ä»–æ‰¹æ¬¡
                    
            except Exception as e:
                print(f"  ğŸ’¥ ç¬¬{batch_num}æ‰¹å¼‚å¸¸: {str(e)[:100]}...")
                continue
        
        return {
            "success": True,
            "result": {
                "analysis_result": all_results
            },
            "total_paragraphs": len(paragraphs_data),
            "processed_paragraphs": len(all_results)
        }
    
    async def _call_ai_api(self, prompt: str) -> str:
        """
        è°ƒç”¨å¤§æ¨¡å‹API
        
        Args:
            prompt: åˆ†æprompt
            
        Returns:
            APIå“åº”æ–‡æœ¬
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£æ ¼å¼åˆ†æä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£åˆ†æWordæ–‡æ¡£æ®µè½ç±»å‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "temperature": 0.1,  # ä½æ¸©åº¦ç¡®ä¿ç¨³å®šè¾“å‡º
            "max_tokens": 3000,
            "response_format": {"type": "json_object"}  # å¯ç”¨JSONæ¨¡å¼
        }
        
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(
                f"{self.api_base_url}/chat/completions",
                headers=headers,
                json=payload
            )
            
            if response.status_code != 200:
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
            
            result = response.json()
            return result["choices"][0]["message"]["content"]
    
    def _parse_ai_response(self, response_text: str) -> Dict[str, Any]:
        """
        è§£æå¤§æ¨¡å‹å“åº”
        
        Args:
            response_text: APIå“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„ç»“æœå­—å…¸
        """
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            if response_text.strip().startswith("{"):
                return json.loads(response_text)
            
            # å°è¯•ä»markdownä»£ç å—ä¸­æå–JSON
            if "```json" in response_text:
                start = response_text.find("```json") + 7
                end = response_text.find("```", start)
                json_text = response_text[start:end].strip()
                return json.loads(json_text)
            
            # å°è¯•ä»```ä»£ç å—ä¸­æå–JSON
            if "```" in response_text:
                start = response_text.find("```") + 3
                end = response_text.find("```", start)
                json_text = response_text[start:end].strip()
                return json.loads(json_text)
            
            # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬
            return {
                "error": "æ— æ³•è§£æå“åº”",
                "raw_response": response_text
            }
            
        except json.JSONDecodeError as e:
            return {
                "error": f"JSONè§£æå¤±è´¥: {str(e)}",
                "raw_response": response_text
            }
    
    def create_mock_analysis(self, paragraphs_data: List[Dict]) -> Dict[str, Any]:
        """
        åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœï¼ˆç”¨äºæµ‹è¯•ï¼‰
        
        Args:
            paragraphs_data: æ®µè½æ•°æ®åˆ—è¡¨
            
        Returns:
            æ¨¡æ‹Ÿçš„åˆ†æç»“æœ
        """
        analysis_result = []
        
        for para in paragraphs_data:
            preview = para["preview_text"]
            para_num = para["paragraph_number"]
            
            # ç®€å•çš„è§„åˆ™åˆ¤æ–­ï¼ˆæ¨¡æ‹ŸAIåˆ†æï¼‰
            if "æ–‡æ¡£" in preview and para_num == 1:
                para_type = "title"
                confidence = 0.95
                reason = "æ–‡æ¡£æ ‡é¢˜ï¼Œä½äºç¬¬ä¸€æ®µ"
            elif preview.startswith("ç¬¬") and "ç« " in preview:
                para_type = "heading1"
                confidence = 0.92
                reason = "ä½¿ç”¨'ç¬¬Xç« 'æ ¼å¼çš„ä¸€çº§æ ‡é¢˜"
            elif preview.count(".") == 1 and preview[0].isdigit():
                para_type = "heading2"
                confidence = 0.88
                reason = "ä½¿ç”¨'X.X'æ ¼å¼çš„äºŒçº§æ ‡é¢˜"
            elif preview.count(".") == 2 and preview[0].isdigit():
                para_type = "heading3"
                confidence = 0.85
                reason = "ä½¿ç”¨'X.X.X'æ ¼å¼çš„ä¸‰çº§æ ‡é¢˜"
            elif len(preview) <= 15 and not preview.endswith("ï¼Œ"):
                para_type = "heading4"
                confidence = 0.75
                reason = "çŸ­æ–‡æœ¬ï¼Œå¯èƒ½æ˜¯ä½çº§æ ‡é¢˜"
            else:
                para_type = "paragraph"
                confidence = 0.80
                reason = "æ­£æ–‡æ®µè½ç‰¹å¾"
            
            analysis_result.append({
                "paragraph_number": para_num,
                "preview_text": preview,
                "type": para_type,
                "confidence": confidence,
                "reason": reason
            })
        
        return {
            "analysis_result": analysis_result
        }
    
    def _ensure_results_dir(self):
        """ç¡®ä¿ç»“æœä¿å­˜ç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
            print(f"ğŸ“ åˆ›å»ºAIåˆ†æç»“æœç›®å½•: {self.results_dir}")
    
    def _save_analysis_result(self, result: Dict[str, Any], paragraphs_data: List[Dict], is_error: bool = False):
        """
        ä¿å­˜AIåˆ†æç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            result: åˆ†æç»“æœ
            paragraphs_data: åŸå§‹æ®µè½æ•°æ®
            is_error: æ˜¯å¦ä¸ºé”™è¯¯ç»“æœ
        """
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            status = "error" if is_error else "success"
            filename = f"ai_analysis_{status}_{timestamp}.json"
            filepath = os.path.join(self.results_dir, filename)
            
            # å‡†å¤‡ä¿å­˜çš„æ•°æ®
            save_data = {
                "timestamp": datetime.now().isoformat(),
                "model": self.model,
                "status": status,
                "input_data": {
                    "total_paragraphs": len(paragraphs_data),
                    "paragraphs": paragraphs_data
                },
                "analysis_result": result,
                "metadata": {
                    "api_base_url": self.api_base_url,
                    "model_name": self.model,
                    "batch_processing": len(paragraphs_data) > 10
                }
            }
            
            # å¦‚æœæ˜¯æˆåŠŸç»“æœï¼Œæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            if not is_error and result.get("success"):
                save_data["statistics"] = self._generate_result_statistics(result)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ AIåˆ†æç»“æœå·²ä¿å­˜: {filepath}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜AIåˆ†æç»“æœå¤±è´¥: {str(e)}")
    
    def _generate_result_statistics(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆåˆ†æç»“æœç»Ÿè®¡ä¿¡æ¯
        
        Args:
            result: åˆ†æç»“æœ
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            analysis_result = result.get("result", {}).get("analysis_result", [])
            
            if not analysis_result:
                return {}
            
            # ç»Ÿè®¡æ®µè½ç±»å‹åˆ†å¸ƒ
            type_count = {}
            confidence_scores = []
            
            for item in analysis_result:
                para_type = item.get("type", "unknown")
                confidence = item.get("confidence", 0)
                
                type_count[para_type] = type_count.get(para_type, 0) + 1
                confidence_scores.append(confidence)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
            
            return {
                "type_distribution": type_count,
                "total_analyzed": len(analysis_result),
                "average_confidence": round(avg_confidence, 3),
                "min_confidence": min(confidence_scores) if confidence_scores else 0,
                "max_confidence": max(confidence_scores) if confidence_scores else 0,
                "most_common_type": max(type_count.items(), key=lambda x: x[1])[0] if type_count else "unknown"
            }
            
        except Exception as e:
            return {"error": f"ç»Ÿè®¡ç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def get_saved_results_list(self) -> List[str]:
        """
        è·å–å·²ä¿å­˜çš„åˆ†æç»“æœæ–‡ä»¶åˆ—è¡¨
        
        Returns:
            æ–‡ä»¶ååˆ—è¡¨
        """
        try:
            if not os.path.exists(self.results_dir):
                return []
            
            files = [f for f in os.listdir(self.results_dir) if f.endswith('.json')]
            files.sort(reverse=True)  # æŒ‰æ—¶é—´å€’åºæ’åˆ—
            return files
            
        except Exception as e:
            print(f"âš ï¸ è·å–ç»“æœæ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def load_saved_result(self, filename: str) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½å·²ä¿å­˜çš„åˆ†æç»“æœ
        
        Args:
            filename: æ–‡ä»¶å
            
        Returns:
            åˆ†æç»“æœæ•°æ®ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            filepath = os.path.join(self.results_dir, filename)
            
            if not os.path.exists(filepath):
                return None
            
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
                
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}")
            return None